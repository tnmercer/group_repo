{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7650aa4-e926-4203-8a94-f4617436e826",
   "metadata": {},
   "source": [
    "# Happy Portfolio Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "638cf160-0471-4a8b-802b-f9f609115dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant libraries\n",
    "\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2703413-4729-44ff-8b32-36453b686ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in etf data from pkl file\n",
    "\n",
    "pkl_file = open('etf_df.pkl', 'rb')\n",
    "dataframe2 = pickle.load(pkl_file)\n",
    "pkl_file.close()\n",
    "\n",
    "# load etf data back into Dataframe\n",
    "all_etf_df = pd.DataFrame(dataframe2)\n",
    "\n",
    "# Convert month end prices to monthly percentage change and drop na values\n",
    "\n",
    "all_etf_df = all_etf_df.pct_change().dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2cee0d5-7ee7-4713-95be-0142b481e8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review dataframe\n",
    "\n",
    " all_etf_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59155082-15e4-45ad-9a48-c2622ccd2f3c",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnpicklingError",
     "evalue": "invalid load key, '\\xe2'.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnpicklingError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_29328\\1818597115.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mpkl_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'wh_2015_2019.pkl'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mdataframe3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpkl_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mpkl_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnpicklingError\u001b[0m: invalid load key, '\\xe2'."
     ]
    }
   ],
   "source": [
    "# Read in country data from pkl file\n",
    "\n",
    "pkl_file = open('wh_2015_2019.pkl', 'rb')\n",
    "dataframe3 = pickle.load(pkl_file)\n",
    "pkl_file.close()\n",
    "\n",
    "# load etf data back into Dataframe\n",
    "wh_2015_2019_df = pd.DataFrame(dataframe3)\n",
    "\n",
    "# Drop Year Column\n",
    "wh_2015_2019_df = wh_2015_2019_df.drop(columns=['Year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697089da-f7ef-42bf-8fd8-44d37c9cdcde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review Dataframe \n",
    "\n",
    "wh_2015_2019_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da54ae4-1b35-43e9-b7c8-ecedf4ffcdcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transpose dataframe to allow mapping to ETFs by Country\n",
    "\n",
    "wh_2015_2019_df = wh_2015_2019_df.transpose()\n",
    "\n",
    "wh_2015_2019_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7745740d-dc6c-4b2a-ad41-979646b92c29",
   "metadata": {},
   "source": [
    "## Portfolio Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8800e84c-4e09-442e-a4f3-a54b1417e654",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Map of ETFs to Countries\n",
    "\n",
    "etf_country_map = {\n",
    "    \"Finland\":\"iShares MSCI Finland Capped\",\n",
    "    \"Denmark\":\"iShares MSCI Denmark Capped\",\n",
    "    \"Norway\":\"iShares MSCI Norway Capped\",\n",
    "    \"Netherlands\":\"iShares MSCI Netherlands\",\n",
    "    \"Switzerland\":\"iShares MSCI Switzerland Capped\",\n",
    "    \"Sweden\":\"iShares MSCI Sweden Capped\",\n",
    "    \"New Zealand\":\"iShares MSCI New Zealand Capped\",\n",
    "    \"Canada\":\"iShares MSCI Canada\",\n",
    "    \"Austria\":\"iShares MSCI Austria Capped\",\n",
    "    \"Australia\":\"iShares MSCI Australia\",\n",
    "    \"Israel\":\"iShares MSCI Israel Capped\",\n",
    "    \"United Kingdom\":\"iShares MSCI United Kingdom\",\n",
    "    \"United States\":\"ishares S&P 500\",\n",
    "    \"Ireland\":\"iShares MSCI Ireland\",\n",
    "    \"Germany\":\"iShares Currency Hedged MSCI Germany\",\n",
    "    \"Mexico\":\"iShares MSCI Mexico Capped\",\n",
    "    \"Benchmark\":\"iShares MSCI World\"\n",
    "}\n",
    "\n",
    "# Create DataFrame of Countries and Corresponding ETFs\n",
    "\n",
    "etf_country_map_df = pd.DataFrame.from_dict(etf_country_map, orient='index')\n",
    "etf_country_map_df.columns = [\"ETF\"]\n",
    "etf_country_map_df.index.name = \"Country\"\n",
    "etf_country_map_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be02e65c-3d70-4a0e-a02e-21fcc28fea61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine Dataframes to show Happiness Score by ETF (for Portfolio Weights)\n",
    "\n",
    "country_etf_combined = pd.merge(etf_country_map_df, wh_2015_2019_df,on='Country', how='outer')\n",
    "\n",
    "country_etf_combined.set_index('ETF', inplace=True, drop=True)\n",
    "columns = [2015,2016,2017,2018,2019]\n",
    "country_etf_combined.columns = columns\n",
    "\n",
    "country_etf_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d705be2-7bf0-432d-b7be-659e286905a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "71847e07-c67f-41b5-9205-028b7f0e035b",
   "metadata": {},
   "source": [
    "# Portfolio Weightings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c543e46b-c189-4838-bcd2-228fa277fb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new Dataframe to weight the ETFs by Happiness Score\n",
    "country_etf_weighted = country_etf_combined\n",
    "\n",
    "\n",
    "# Recalculate Dataframe to Weight each Score by Year\n",
    "\n",
    "country_etf_weighted[\"2015 Weights\"] = (country_etf_weighted[2015]/country_etf_weighted[2015].sum()) * 100\n",
    "country_etf_weighted[\"2016 Weights\"] = (country_etf_weighted[2016]/country_etf_weighted[2016].sum()) * 100\n",
    "country_etf_weighted[\"2017 Weights\"] = (country_etf_weighted[2017]/country_etf_weighted[2017].sum()) * 100\n",
    "country_etf_weighted[\"2018 Weights\"] = (country_etf_weighted[2018]/country_etf_weighted[2018].sum()) * 100\n",
    "country_etf_weighted[\"2019 Weights\"] = (country_etf_weighted[2019]/country_etf_weighted[2019].sum()) * 100\n",
    "\n",
    "# Drop original score columns to leave only the portfolio weights\n",
    "country_etf_weighted = country_etf_weighted.drop(columns=[2015,2016,2017,2018,2019])\n",
    "\n",
    "# Rename the columns\n",
    "columns = [2015,2016,2017,2018,2019]\n",
    "country_etf_weighted.columns = columns\n",
    "\n",
    "# Review the weighted DataFrame\n",
    "country_etf_weighted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b26bd5-2bce-4525-8cc0-02f4495b1140",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check all columns total 100\n",
    "country_etf_weighted.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0a05f8-6270-4cad-bbfb-ce5d2450a6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "donut_2015 = pd.DataFrame(country_etf_weighted[2015].dropna())\n",
    "donut_2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6751bbde-7942-45e4-8858-ef86f6e52709",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use `hole` to create a donut-like pie chart\n",
    "\n",
    "names = [\n",
    "    \"Finland\", \n",
    "    \"Denmark\", \n",
    "    \"Norway\", \n",
    "    \"Netherlands\",\n",
    "    \"Switzerland\",\n",
    "    \"Sweden\",\n",
    "    \"New Zealand\",\n",
    "    \"Canada\",\n",
    "    \"Austria\",\n",
    "    \"Australia\",\n",
    "    \"Israel\",\n",
    "    \"United States\",\n",
    "    \"Mexico\"]\n",
    "\n",
    "fig = px.pie(\n",
    "    donut_2015, \n",
    "    values=2015, \n",
    "    names=names, \n",
    "    title='Porfolio Weights', \n",
    "    hole=0.5,\n",
    "    hover_data=[2015],\n",
    ")\n",
    "\n",
    "fig.update_traces(\n",
    "    textposition='outside',\n",
    "    textinfo='label'\n",
    ")\n",
    "\n",
    "for template in [\"plotly_dark\"]:\n",
    "    fig.update_layout(template=template, annotations=[dict(text='2015', x=0.5, y=0.5, font_size=20, showarrow=False)])\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c881ffa-8ba2-4f67-8de3-6f9e0d0d8b2b",
   "metadata": {},
   "source": [
    "## Portfolio Return\n",
    "\n",
    "### 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decf5f6b-2ca1-4322-b1ad-02bbf7ebb97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set starting values for 2015 based on weight\n",
    "portfolio_start_2015 = country_etf_weighted.iloc[:,0]\n",
    "\n",
    "# Check total = 100\n",
    "display(portfolio_start_2015.sum())\n",
    "\n",
    "# Create new dataframe for 2015 return calc using the 2015 start values\n",
    "portfolio_return_2015 = pd.DataFrame(portfolio_start_2015)\n",
    "portfolio_return_2015 = portfolio_return_2015.transpose()\n",
    "\n",
    "# Rename weighted value index to start date 01-01-2015\n",
    "portfolio_return_2015 = portfolio_return_2015.reset_index(drop=True)\n",
    "portfolio_return_2015 = portfolio_return_2015.rename(index={0:'2015-01-01'})\n",
    "\n",
    "# Append the all_etf_df monthly returns\n",
    "portfolio_return_2015 = portfolio_return_2015.append(all_etf_df.loc['2015-02-01':'2015-12-31']).sort_index()\n",
    "\n",
    "# Calculate cumulative return and drop na row\n",
    "portfolio_return_2015 = (1 + portfolio_return_2015.shift(1)).cumprod().dropna(how='all')\n",
    "\n",
    "# Drop ETFs not included in portfolio for 2015\n",
    "portfolio_return_2015 = portfolio_return_2015.dropna(axis=1)\n",
    "\n",
    "# Review the dataframe\n",
    "portfolio_return_2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5060e946-f798-4be0-9481-0e2965980465",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new benchmark dataframe, rebase to 100 for comparible data to portfolio\n",
    "\n",
    "benchmark = pd.DataFrame(index=[\"Benchmark\"], data=[100], columns=[\"2015-01-01\"])\n",
    "\n",
    "# Append benchmark data from all_etf_df and combine into a single columns\n",
    "\n",
    "benchmark = benchmark.append(all_etf_df[\"iShares MSCI World\"])\n",
    "benchmark = benchmark.transpose().sum(axis=1)\n",
    "\n",
    "# Slice by date \n",
    "benchmark = benchmark.loc[\"2015-01-01\":\"2015-12-31\"]\n",
    "\n",
    "# Calculate cumulative return and drop na (first value)\n",
    "benchmark = (1 + benchmark.shift(1)).cumprod().dropna()\n",
    "benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c86fc4-8a9a-4dc1-96a9-1fd60dc9a12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine return for portfolio\n",
    "\n",
    "portfolio_return_2015 = portfolio_return_2015.sum(axis=1)\n",
    "portfolio_return_2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fe6865-b4d3-47e0-84cd-12ac105bd498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create plot dataframe by combining benchmark and portfolio return dfs\n",
    "\n",
    "plot_df = pd.concat([portfolio_return_2015, benchmark.loc[\"2015-01-01\":\"2015-12-31\"]], axis=1)\n",
    "\n",
    "# Rename columns\n",
    "columns = [\"Happy Portfolio\",\"Benchmark\"]\n",
    "plot_df.columns = columns\n",
    "\n",
    "# Add back in the start value of 100 for the plot\n",
    "new_row = pd.DataFrame({\"Happy Portfolio\":100, \"Benchmark\":100}, index=['2015-01-01'])\n",
    "plot_df = pd.concat([plot_df, new_row]).sort_index()\n",
    "\n",
    "# Review\n",
    "plot_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33bfb469-7baa-4ee3-a8bc-7ee96ec4bd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 2015\n",
    "\n",
    "fig = px.line(\n",
    "    plot_df,\n",
    "    title=\"2015\",\n",
    "    height=500,\n",
    "    width=1000,\n",
    "    labels={\n",
    "        \"value\":\"Return\",\n",
    "        \"index\":\"Date\",\n",
    "        \"variable\":\"Happy Portfolio\"\n",
    "    }\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7b37e2-372f-4cca-9430-a8fc57642911",
   "metadata": {},
   "source": [
    "### 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e724f76-a9cb-4348-b264-13b9af72ed9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set starting values for 2016 based on 2015 year end value and 2016 weights\n",
    "portfolio_start_2016 = portfolio_return_2015[-1] / 100 * country_etf_weighted.iloc[:,1]\n",
    "\n",
    "# Check total = 2015 year end value $111.69\n",
    "display(portfolio_start_2016.sum())\n",
    "\n",
    "# Create new dataframe for 2016 return calc using the 2016 start values\n",
    "portfolio_return_2016 = pd.DataFrame(index=[\"2015-12-31\"],data=[portfolio_start_2016])\n",
    "\n",
    "# # Rename weighted value index to start date 01-01-2015\n",
    "# portfolio_return_2015 = portfolio_return_2015.reset_index(drop=True)\n",
    "# portfolio_return_2015 = portfolio_return_2015.rename(index={0:'2015-01-01'})\n",
    "\n",
    "# Append the all_etf_df monthly returns\n",
    "portfolio_return_2016 = portfolio_return_2016.append(all_etf_df.loc['2016-01-01':'2016-12-31']).sort_index()\n",
    "\n",
    "# Calculate cumulative return and drop na row\n",
    "portfolio_return_2016 = (1 + portfolio_return_2016.shift(1)).cumprod().dropna(how='all')\n",
    "\n",
    "# Drop ETFs not included in portfolio for 2015\n",
    "portfolio_return_2016 = portfolio_return_2016.dropna(axis=1)\n",
    "\n",
    "# Review the dataframe\n",
    "portfolio_return_2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4054a08-e971-4432-bcf9-934e732c39c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extend benchmark to 2016 - once all consolidated use one code for Benchmark\n",
    "\n",
    "# Create a new benchmark dataframe, rebase to 100 for comparible data to portfolio\n",
    "\n",
    "benchmark = pd.DataFrame(index=[\"Benchmark\"], data=[100], columns=[\"2015-01-01\"])\n",
    "\n",
    "# Append benchmark data from all_etf_df and combine into a single columns\n",
    "\n",
    "benchmark = benchmark.append(all_etf_df[\"iShares MSCI World\"])\n",
    "benchmark = benchmark.transpose().sum(axis=1)\n",
    "\n",
    "# Slice by date \n",
    "benchmark = benchmark.loc[\"2015-01-01\":\"2016-12-31\"]\n",
    "\n",
    "# Calculate cumulative return and drop na (first value)\n",
    "benchmark = (1 + benchmark.shift(1)).cumprod().dropna()\n",
    "benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78b07ea-f11a-409e-8143-a74163c2a396",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine return for portfolio\n",
    "\n",
    "portfolio_return_2016 = portfolio_return_2016.sum(axis=1)\n",
    "portfolio_return_2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73227896-6805-4d19-bb26-bdfc1e2c66ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create plot dataframe by combining benchmark and portfolio return dfs\n",
    "\n",
    "plot_df_2016 = pd.concat([portfolio_return_2015, portfolio_return_2016], axis=0)\n",
    "\n",
    "plot_df_2016 = pd.concat([plot_df_2016, benchmark.loc[\"2015-01-01\":\"2016-12-31\"]], axis=1)\n",
    "\n",
    "# Rename columns\n",
    "columns = [\"Happy Portfolio\",\"Benchmark\"]\n",
    "plot_df_2016.columns = columns\n",
    "\n",
    "# Add back in the start value of 100 for the plot\n",
    "new_row = pd.DataFrame({\"Happy Portfolio\":100, \"Benchmark\":100}, index=['2015-01-01'])\n",
    "plot_df_2016 = pd.concat([plot_df_2016, new_row]).sort_index()\n",
    "\n",
    "# Review\n",
    "plot_df_2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbdac1f7-2220-451e-b21f-2462d93bb90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 2015-2016\n",
    "\n",
    "fig = px.line(\n",
    "    plot_df_2016,\n",
    "    title=\"2015-2016\",\n",
    "    height=500,\n",
    "    width=1000,\n",
    "    labels={\n",
    "        \"value\":\"Return\",\n",
    "        \"index\":\"Date\",\n",
    "        \"variable\":\"Happy Portfolio\"\n",
    "    }\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d613c60f-6966-4435-9289-851b69ab8dc4",
   "metadata": {},
   "source": [
    "## 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784ca8bc-5136-4068-9c90-765373805563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set starting values for 2017 based on 2016 year end value and 2017 weights\n",
    "portfolio_start_2017 = portfolio_return_2016[-1] / 100 * country_etf_weighted.iloc[:,2]\n",
    "\n",
    "# Check total = 2016 year end value $126.55\n",
    "display(portfolio_start_2017.sum())\n",
    "\n",
    "# Create new dataframe for 2017 return calc using the 2017 start values\n",
    "portfolio_return_2017 = pd.DataFrame(index=[\"2016-12-31\"],data=[portfolio_start_2017])\n",
    "\n",
    "# # Rename weighted value index to start date 01-01-2015\n",
    "# portfolio_return_2015 = portfolio_return_2015.reset_index(drop=True)\n",
    "# portfolio_return_2015 = portfolio_return_2015.rename(index={0:'2015-01-01'})\n",
    "\n",
    "# Append the all_etf_df monthly returns\n",
    "portfolio_return_2017 = portfolio_return_2017.append(all_etf_df.loc['2017-01-01':'2017-12-31']).sort_index()\n",
    "\n",
    "# Calculate cumulative return and drop na row\n",
    "portfolio_return_2017 = (1 + portfolio_return_2017.shift(1)).cumprod().dropna(how='all')\n",
    "\n",
    "# Drop ETFs not included in portfolio for 2015\n",
    "portfolio_return_2017 = portfolio_return_2017.dropna(axis=1)\n",
    "\n",
    "# Review the dataframe\n",
    "portfolio_return_2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2aad6bf-96ac-468e-b18b-05c4137921ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extend benchmark to 2017 - once all consolidated use one code for Benchmark\n",
    "\n",
    "# Create a new benchmark dataframe, rebase to 100 for comparible data to portfolio\n",
    "\n",
    "benchmark = pd.DataFrame(index=[\"Benchmark\"], data=[100], columns=[\"2015-01-01\"])\n",
    "\n",
    "# Append benchmark data from all_etf_df and combine into a single columns\n",
    "\n",
    "benchmark = benchmark.append(all_etf_df[\"iShares MSCI World\"])\n",
    "benchmark = benchmark.transpose().sum(axis=1)\n",
    "\n",
    "# Slice by date \n",
    "benchmark = benchmark.loc[\"2015-01-01\":\"2017-12-31\"]\n",
    "\n",
    "# Calculate cumulative return and drop na (first value)\n",
    "benchmark = (1 + benchmark.shift(1)).cumprod().dropna()\n",
    "benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520faffa-a96e-434d-ab79-5dc3e3c5dd55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine return for portfolio\n",
    "\n",
    "portfolio_return_2017 = portfolio_return_2017.sum(axis=1)\n",
    "portfolio_return_2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32c2d5d-8390-44ae-aaa8-a7d6890fc397",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create plot dataframe by combining benchmark and portfolio return dfs\n",
    "\n",
    "plot_df_2017 = pd.concat([portfolio_return_2015, portfolio_return_2016, portfolio_return_2017], axis=0)\n",
    "\n",
    "plot_df_2017 = pd.concat([plot_df_2017, benchmark.loc[\"2015-01-01\":\"2017-12-31\"]], axis=1)\n",
    "\n",
    "# Rename columns\n",
    "columns = [\"Happy Portfolio\",\"Benchmark\"]\n",
    "plot_df_2017.columns = columns\n",
    "\n",
    "# Add back in the start value of 100 for the plot\n",
    "new_row = pd.DataFrame({\"Happy Portfolio\":100, \"Benchmark\":100}, index=['2015-01-01'])\n",
    "plot_df_2017 = pd.concat([plot_df_2017, new_row]).sort_index()\n",
    "\n",
    "# Review\n",
    "plot_df_2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365ec116-0f43-442f-9d4d-c7c9b30d290e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 2015-2017\n",
    "\n",
    "fig = px.line(\n",
    "    plot_df_2017,\n",
    "    title=\"2015-2017\",\n",
    "    height=500,\n",
    "    width=1000,\n",
    "    labels={\n",
    "        \"value\":\"Return\",\n",
    "        \"index\":\"Date\",\n",
    "        \"variable\":\"Happy Portfolio\"\n",
    "    }\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb77bc1-dbeb-44a5-9e42-18f810de758e",
   "metadata": {},
   "source": [
    "## 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910b8a26-193c-4991-a6fe-3f071587c118",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set starting values for 2018 based on 2017 year end value and 2018 weights\n",
    "portfolio_start_2018 = portfolio_return_2017[-1] / 100 * country_etf_weighted.iloc[:,3]\n",
    "\n",
    "# Check total = 2017 year end value $168.07\n",
    "display(portfolio_start_2018.sum())\n",
    "\n",
    "# Create new dataframe for 2018 return calc using the 2018 start values\n",
    "portfolio_return_2018 = pd.DataFrame(index=[\"2017-12-31\"],data=[portfolio_start_2018])\n",
    "\n",
    "# # Rename weighted value index to start date 01-01-2015\n",
    "# portfolio_return_2015 = portfolio_return_2015.reset_index(drop=True)\n",
    "# portfolio_return_2015 = portfolio_return_2015.rename(index={0:'2015-01-01'})\n",
    "\n",
    "# Append the all_etf_df monthly returns\n",
    "portfolio_return_2018 = portfolio_return_2018.append(all_etf_df.loc['2018-01-01':'2018-12-31']).sort_index()\n",
    "\n",
    "# Calculate cumulative return and drop na row\n",
    "portfolio_return_2018 = (1 + portfolio_return_2018.shift(1)).cumprod().dropna(how='all')\n",
    "\n",
    "# Drop ETFs not included in portfolio for 2018\n",
    "portfolio_return_2018 = portfolio_return_2018.dropna(axis=1)\n",
    "\n",
    "# Review the dataframe\n",
    "portfolio_return_2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8068f2c-ff69-431c-9bf4-4552395a9c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extend benchmark to 2018 - once all consolidated use one code for Benchmark\n",
    "\n",
    "# Create a new benchmark dataframe, rebase to 100 for comparible data to portfolio\n",
    "\n",
    "benchmark = pd.DataFrame(index=[\"Benchmark\"], data=[100], columns=[\"2015-01-01\"])\n",
    "\n",
    "# Append benchmark data from all_etf_df and combine into a single columns\n",
    "\n",
    "benchmark = benchmark.append(all_etf_df[\"iShares MSCI World\"])\n",
    "benchmark = benchmark.transpose().sum(axis=1)\n",
    "\n",
    "# Slice by date \n",
    "benchmark = benchmark.loc[\"2015-01-01\":\"2018-12-31\"]\n",
    "\n",
    "# Calculate cumulative return and drop na (first value)\n",
    "benchmark = (1 + benchmark.shift(1)).cumprod().dropna()\n",
    "benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc1bb41-fc2e-4601-8060-8522f072d6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine return for portfolio\n",
    "\n",
    "portfolio_return_2018 = portfolio_return_2018.sum(axis=1)\n",
    "portfolio_return_2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e84b3d-8c81-4da7-bcd0-cd45d225e19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create plot dataframe by combining benchmark and portfolio return dfs\n",
    "\n",
    "plot_df_2018 = pd.concat([portfolio_return_2015, portfolio_return_2016, portfolio_return_2017, portfolio_return_2018], axis=0)\n",
    "\n",
    "plot_df_2018 = pd.concat([plot_df_2018, benchmark.loc[\"2015-01-01\":\"2018-12-31\"]], axis=1)\n",
    "\n",
    "# Rename columns\n",
    "columns = [\"Happy Portfolio\",\"Benchmark\"]\n",
    "plot_df_2018.columns = columns\n",
    "\n",
    "# Add back in the start value of 100 for the plot\n",
    "new_row = pd.DataFrame({\"Happy Portfolio\":100, \"Benchmark\":100}, index=['2015-01-01'])\n",
    "plot_df_2018 = pd.concat([plot_df_2018, new_row]).sort_index()\n",
    "\n",
    "# Review\n",
    "plot_df_2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722982bb-ed38-4d43-bc92-9e7ace396fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 2015-2018\n",
    "\n",
    "fig = px.line(\n",
    "    plot_df_2018,\n",
    "    title=\"Growth of $100 invested 2015-2018\",\n",
    "    height=500,\n",
    "    width=1000,\n",
    "    labels={\n",
    "        \"value\":\"Return\",\n",
    "        \"index\":\"Date\",\n",
    "        \"variable\":\"Happy Portfolio\"\n",
    "    }\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d05e689-e2ea-4de3-8c0b-96bddaa57cf7",
   "metadata": {},
   "source": [
    "## 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858d5371-3a59-4567-b0dc-d20a7cf7af93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set starting values for 2019 based on 2018 year end value and 2019 weights\n",
    "portfolio_start_2019 = portfolio_return_2018[-1] / 100 * country_etf_weighted.iloc[:,3]\n",
    "\n",
    "# Check total = 2018 year end value $162.80\n",
    "display(portfolio_start_2019.sum())\n",
    "\n",
    "# Create new dataframe for 2019 return calc using the 2019 start values\n",
    "portfolio_return_2019 = pd.DataFrame(index=[\"2018-12-31\"],data=[portfolio_start_2019])\n",
    "\n",
    "# # Rename weighted value index to start date 01-01-2015\n",
    "# portfolio_return_2015 = portfolio_return_2015.reset_index(drop=True)\n",
    "# portfolio_return_2015 = portfolio_return_2015.rename(index={0:'2015-01-01'})\n",
    "\n",
    "# Append the all_etf_df monthly returns\n",
    "portfolio_return_2019 = portfolio_return_2019.append(all_etf_df.loc['2019-01-01':'2019-12-31']).sort_index()\n",
    "\n",
    "# Calculate cumulative return and drop na row\n",
    "portfolio_return_2019 = (1 + portfolio_return_2019.shift(1)).cumprod().dropna(how='all')\n",
    "\n",
    "# Drop ETFs not included in portfolio for 2019\n",
    "portfolio_return_2019 = portfolio_return_2019.dropna(axis=1)\n",
    "\n",
    "# Review the dataframe\n",
    "portfolio_return_2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd251d50-8149-4533-bfc9-89952d1cd210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extend benchmark to 2019 - once all consolidated use one code for Benchmark\n",
    "\n",
    "# Create a new benchmark dataframe, rebase to 100 for comparible data to portfolio\n",
    "\n",
    "benchmark = pd.DataFrame(index=[\"Benchmark\"], data=[100], columns=[\"2015-01-01\"])\n",
    "\n",
    "# Append benchmark data from all_etf_df and combine into a single columns\n",
    "\n",
    "benchmark = benchmark.append(all_etf_df[\"iShares MSCI World\"])\n",
    "benchmark = benchmark.transpose().sum(axis=1)\n",
    "\n",
    "# Slice by date \n",
    "benchmark = benchmark.loc[\"2015-01-01\":\"2019-12-31\"]\n",
    "\n",
    "# Calculate cumulative return and drop na (first value)\n",
    "benchmark = (1 + benchmark.shift(1)).cumprod().dropna()\n",
    "benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4558386c-a055-4dd7-b04f-62e34f178198",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine return for portfolio\n",
    "\n",
    "portfolio_return_2019 = portfolio_return_2019.sum(axis=1)\n",
    "portfolio_return_2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883b3003-329a-41bd-bf19-da15c290cbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create plot dataframe by combining benchmark and portfolio return dfs\n",
    "\n",
    "plot_df_2019 = pd.concat([portfolio_return_2015, portfolio_return_2016, portfolio_return_2017, portfolio_return_2018, portfolio_return_2019], axis=0)\n",
    "\n",
    "plot_df_2019 = pd.concat([plot_df_2019, benchmark.loc[\"2015-01-01\":\"2019-12-31\"]], axis=1)\n",
    "\n",
    "# Rename columns\n",
    "columns = [\"Happy Portfolio\",\"Benchmark\"]\n",
    "plot_df_2019.columns = columns\n",
    "\n",
    "# Add back in the start value of 100 for the plot\n",
    "new_row = pd.DataFrame({\"Happy Portfolio\":100, \"Benchmark\":100}, index=['2015-01-01'])\n",
    "plot_df_2019 = pd.concat([plot_df_2019, new_row]).sort_index()\n",
    "\n",
    "# Review\n",
    "plot_df_2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14025b41-0363-4529-ad57-ba184732ff50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 2015-2019\n",
    "\n",
    "fig = px.line(\n",
    "    plot_df_2019,\n",
    "    title=\"Growth of $100 invested 2015-2019\",\n",
    "    height=500,\n",
    "    width=1000,\n",
    "    labels={\n",
    "        \"value\":\"Return\",\n",
    "        \"index\":\"Date\",\n",
    "        \"variable\":\"Happy Portfolio\"\n",
    "    }\n",
    ")\n",
    "\n",
    "for template in [\"plotly_dark\"]:\n",
    "    fig.update_layout(template=template)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf788c74-b173-4725-9b55-2e2bd63cd6b7",
   "metadata": {},
   "source": [
    "## Review calcs needed from here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629408e3-54fd-444d-a90a-d782d03e3cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Annual Return\n",
    "all_etf_df_return_2015 = all_etf_df.loc['2015-01-01':'2015-12-31'].mean() * 12\n",
    "all_etf_df_return_2015 = pd.DataFrame(all_etf_df_return_2015, columns=[2015])\n",
    "\n",
    "all_etf_df_return_2016 = all_etf_df.loc['2016-01-01':'2016-12-31'].mean() * 12\n",
    "all_etf_df_return_2016 = pd.DataFrame(all_etf_df_return_2016, columns=[2016])\n",
    "\n",
    "all_etf_df_return_2017 = all_etf_df.loc['2017-01-01':'2017-12-31'].mean() * 12\n",
    "all_etf_df_return_2017 = pd.DataFrame(all_etf_df_return_2017, columns=[2017])\n",
    "\n",
    "all_etf_df_return_2018 = all_etf_df.loc['2018-01-01':'2018-12-31'].mean() * 12\n",
    "all_etf_df_return_2018 = pd.DataFrame(all_etf_df_return_2018, columns=[2018])\n",
    "\n",
    "all_etf_df_return_2019 = all_etf_df.loc['2019-01-01':'2019-12-31'].mean() * 12\n",
    "all_etf_df_return_2019 = pd.DataFrame(all_etf_df_return_2019, columns=[2019])\n",
    "\n",
    "etf_annual_returns = pd.concat([all_etf_df_return_2015, all_etf_df_return_2016, all_etf_df_return_2017, all_etf_df_return_2018, all_etf_df_return_2019], axis=1)\n",
    "\n",
    "etf_annual_returns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c47d86-e8f9-419b-b36b-02e03984c311",
   "metadata": {},
   "source": [
    "## Monthly Portfolio Return vs Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e84fe2-f01a-406e-9400-ba8ca94a6077",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty dataframe to collect portfolio weights from below for loop\n",
    "portfolio_2019_df = pd.DataFrame()\n",
    "\n",
    "# Return * Portfolio Weight\n",
    "for etf in portfolio_weight_2019:\n",
    "    etf_column = all_etf_df[etf] * portfolio_weight_2019[etf]\n",
    "    portfolio_2019_df[etf] = etf_column\n",
    "\n",
    "# Filter Dates\n",
    "portfolio_2019_df = portfolio_2019_df.loc['2019-01-01':'2019-12-31']\n",
    "    \n",
    "# Combined return for all funds and rename Happy Portfolio\n",
    "portfolio_2019_df = pd.DataFrame(portfolio_2019_df.sum(axis=1), columns=['Happy Portfolio'])\n",
    "\n",
    "# Add Benchmark\n",
    "benchmark = \"iShares MSCI World\"\n",
    "\n",
    "benchmark_return = pd.DataFrame(all_etf_df[benchmark])\n",
    "\n",
    "# slice by date\n",
    "benchmark_return = benchmark_return.loc[\"2019-01-01\":\"2019-12-31\"]\n",
    "\n",
    "portfolio_2019_df = pd.concat([portfolio_2019_df,benchmark_return], axis=1)\n",
    "portfolio_2019_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a84d06-5988-4246-a25b-4d35b3967ca8",
   "metadata": {},
   "source": [
    "## Cumulative Portfolio Return vs Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf718509-1df5-4b4e-9d89-e4e34d842047",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cumulative returns\n",
    "cum_portfolio_2019 = (1 + portfolio_2019_df).cumprod()\n",
    "cum_portfolio_2019\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152b6193-380f-4343-b61e-9daea947f893",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 2019 vs benchmark\n",
    "\n",
    "fig = px.line(\n",
    "    cum_portfolio_2019,\n",
    "    title=\"Cumulative Return of Happy Portfolio vs Benchmark 2019\",\n",
    "    height=500,\n",
    "    width=1000,\n",
    "    labels={\n",
    "        \"value\":\"Return\",\n",
    "        \"date\":\"Date\",\n",
    "        \"variable\":\"\"\n",
    "    }\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dbc080c-0ebd-407a-9c44-c7332da5c8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Portfolio and Benchmark Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36ecf20-eab1-4150-858f-3ef5b7383fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "portfolio_2019_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8be938-9647-4934-9f32-fc45b527b7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.box(\n",
    "    portfolio_2019_df,\n",
    "    title='Box Plot of Happy Portfolio and Benchmark Returns'\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1443c9eb-e3ec-4cd2-8002-a77976be9c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sharpe Ratio\n",
    "\n",
    "average_annual_return = portfolio_2019_df.mean() * 12\n",
    "display(average_annual_return)\n",
    "\n",
    "annual_sd_portfolio = portfolio_2019_df.std() * np.sqrt(12)\n",
    "display(annual_sd_portfolio)\n",
    "\n",
    "sharpe_ratios = average_annual_return / annual_sd_portfolio\n",
    "display(sharpe_ratios)\n",
    "\n",
    "fig = px.bar(\n",
    "    sharpe_ratios,\n",
    "    title=\"Sharpe Ratios of Happy Fund and Benchmark\"\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58bf3ad9-a499-417b-a7d6-18e180465f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PULL IN WORLD HAPPINESS DF TO OBTAIN RANKINGS OR SCORE\n",
    "# CREATE WEIGHTINGS VARIABLES PER YEAR\n",
    "# CREATE PERFORMANCE VARIABLES BY YEAR BASED ON WEIGHTINGS AND RANKINGS \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dev)",
   "language": "python",
   "name": "dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
